{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# PEFT for Text Summarization\n\nThis notebook fine-tunes a transformer model using Parameter-Efficient Fine-Tuning techniques."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install transformers datasets peft\n", "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer\n", "from datasets import load_dataset\n", "import torch\n", "\n", "# Load dataset\n", "dataset = load_dataset('cnn_dailymail', '3.0.0')\n", "\n", "# Load model and tokenizer\n", "model_name = 'facebook/bart-large-cnn'\n", "tokenizer = AutoTokenizer.from_pretrained(model_name)\n", "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n", "\n", "# Example summarization\n", "article = dataset['test'][0]['article']\n", "inputs = tokenizer(article, return_tensors='pt', max_length=1024, truncation=True)\n", "summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=50, length_penalty=2.0, num_beams=4)\n", "print(tokenizer.decode(summary_ids[0], skip_special_tokens=True))"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 4}